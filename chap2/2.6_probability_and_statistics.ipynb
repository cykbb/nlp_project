{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1cacfa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "from torch.distributions.multinomial import Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7782c09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heads, tails:  [518, 482]\n"
     ]
    }
   ],
   "source": [
    "num_tosses = 1000\n",
    "heads = sum([random.random() > 0.5 for _ in range(num_tosses)])\n",
    "tails = num_tosses - heads\n",
    "print(\"heads, tails: \", [heads, tails])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3a2053a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([47., 53.])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fair_probs = torch.tensor([0.5, 0.5])\n",
    "Multinomial(100, fair_probs).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3125932a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4000, 0.6000])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Multinomial(100, fair_probs).sample() / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b08c9d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5032, 0.4968])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = Multinomial(10000, fair_probs).sample()\n",
    "counts / 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec808331",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 1. 贝叶斯公式的推导\n",
    "\n",
    "* 条件概率的定义：\n",
    "\n",
    "  $$\n",
    "  P(A,B) = P(A|B)P(B) = P(B|A)P(A)\n",
    "  $$\n",
    "* 两边相等，得到：\n",
    "\n",
    "  $$\n",
    "  P(A|B) = \\frac{P(B|A)P(A)}{P(B)}.\n",
    "  $$\n",
    "* 这就是经典的 **贝叶斯公式**。\n",
    "\n",
    "---\n",
    "\n",
    "## 2. 贝叶斯公式的直观意义\n",
    "\n",
    "* 它可以 **反转条件概率的方向**。\n",
    "  通常我们容易得到 $P(B|A)$（例如：已知疾病 $A$ 时出现症状 $B$ 的概率），但我们真正想要的是 $P(A|B)$（出现症状后有病的概率）。\n",
    "* 贝叶斯公式帮我们通过 $P(B|A)$、先验 $P(A)$、以及边缘概率 $P(B)$ 计算出需要的 $P(A|B)$。\n",
    "\n",
    "---\n",
    "\n",
    "## 3. 简化版公式\n",
    "\n",
    "有时候我们不知道 $P(B)$，但可以用比例的方式写：\n",
    "\n",
    "$$\n",
    "P(A|B) \\propto P(B|A)P(A).\n",
    "$$\n",
    "\n",
    "* 意思是：后验概率和“似然 × 先验”成正比。\n",
    "* 最后还要通过归一化确保所有可能的 $A$ 概率和为 1。\n",
    "\n",
    "---\n",
    "\n",
    "## 4. 归一化（正规化）\n",
    "\n",
    "为了把“成比例”变成“等于”，需要归一化：\n",
    "\n",
    "$$\n",
    "P(A|B) = \\frac{P(B|A)P(A)}{\\sum_a P(B|A=a)P(A=a)}.\n",
    "$$\n",
    "\n",
    "* 分母就是所有可能 $A$ 的情况求和，保证结果是一个真正的概率分布。\n",
    "\n",
    "---\n",
    "\n",
    "## 5. 在贝叶斯统计里的解释\n",
    "\n",
    "* **Prior 先验** $P(H)$：在看到数据前，对假设 $H$ 的主观信念。\n",
    "* **Likelihood 似然** $P(E|H)$：如果假设 $H$ 成立，看到证据 $E$ 的可能性。\n",
    "* **Posterior 后验** $P(H|E)$：看到数据后，更新对假设的信念。\n",
    "* 公式：\n",
    "\n",
    "  $$\n",
    "  P(H|E) = \\frac{P(E|H)P(H)}{P(E)}.\n",
    "  $$\n",
    "\n",
    "  可以理解为：**后验 = 先验 × 似然 ÷ 证据**。\n",
    "\n",
    "---\n",
    "\n",
    "## 6. 边缘化 (Marginalization)\n",
    "\n",
    "分母 $P(E)$ 实际上是把所有可能的假设都考虑进来：\n",
    "\n",
    "$$\n",
    "P(E) = \\sum_H P(E|H)P(H).\n",
    "$$\n",
    "\n",
    "这个求和过程叫做 **边缘化**，本质就是把联合概率 $P(E,H)$ 对 $H$ 求和，得到边缘分布 $P(E)$。\n",
    "\n",
    "---\n",
    "\n",
    "## 7. 小结\n",
    "\n",
    "* 贝叶斯公式 = 条件概率公式的直接推论。\n",
    "* 它的价值在于**反转条件概率方向**，把 $P(B|A)$ 变成 $P(A|B)$。\n",
    "* 在贝叶斯统计里：\n",
    "\n",
    "  * **先验**：主观信念。\n",
    "  * **似然**：假设解释数据的能力。\n",
    "  * **后验**：结合数据更新后的信念。\n",
    "* 分母 $P(B)$ 通过边缘化得到，确保归一化。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7038d5",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 1. 什么是期望 (Expectation)\n",
    "\n",
    "* 期望就是“平均结果”。\n",
    "* 在随机变量 $X$ 上，它表示 **长期重复实验时的平均值**。\n",
    "* 定义（离散型）：\n",
    "\n",
    "  $$\n",
    "  E[X] = \\sum_x x \\, P(X=x).\n",
    "  $$\n",
    "* 定义（连续型）：\n",
    "\n",
    "  $$\n",
    "  E[X] = \\int x \\, p(x)\\, dx.\n",
    "  $$\n",
    "\n",
    "例子：投资可能 50% 完全失败 (收益 0)，40% 有 2 倍收益，10% 有 10 倍收益：\n",
    "\n",
    "$$\n",
    "E[X] = 0.5\\cdot 0 + 0.4\\cdot 2 + 0.1\\cdot 10 = 1.8.\n",
    "$$\n",
    "\n",
    "所以期望回报是 1.8 倍。\n",
    "\n",
    "---\n",
    "\n",
    "## 2. 函数的期望\n",
    "\n",
    "不仅可以算随机变量本身的期望，还可以算它的函数 $f(X)$ 的期望：\n",
    "\n",
    "$$\n",
    "E[f(X)] = \\sum_x f(x)P(x)\\quad\\text{或}\\quad \\int f(x)p(x)\\, dx.\n",
    "$$\n",
    "\n",
    "在经济学里，这个 $f$ 常常表示 **效用函数 (utility)**，即“幸福感”。\n",
    "\n",
    "* 人们对钱的效用往往是**非线性**的（损失更痛苦，收益边际递减）。\n",
    "* 例如“金钱效用是对数函数”的说法，就是这个原因。\n",
    "\n",
    "---\n",
    "\n",
    "## 3. 投资效用的例子\n",
    "\n",
    "如果设定：\n",
    "\n",
    "* 完全失败：效用 = -1\n",
    "* 收益 1 倍 → 效用 1\n",
    "* 收益 2 倍 → 效用 2\n",
    "* 收益 10 倍 → 效用 4\n",
    "\n",
    "那么期望效用：\n",
    "\n",
    "$$\n",
    "E[f(X)] = 0.5\\cdot (-1) + 0.4\\cdot 2 + 0.1\\cdot 4 = 0.7.\n",
    "$$\n",
    "\n",
    "代表预期幸福值是 **负的**（比不投资更糟），所以理性的选择可能是不要投资。\n",
    "\n",
    "---\n",
    "\n",
    "## 4. 风险与方差 (Variance)\n",
    "\n",
    "除了期望，还要考虑 **风险性**，即结果波动有多大。\n",
    "\n",
    "* 定义：\n",
    "\n",
    "  $$\n",
    "  \\text{Var}[X] = E\\left[(X-E[X])^2\\right] = E[X^2] - (E[X])^2.\n",
    "  $$\n",
    "* 标准差 $\\sigma = \\sqrt{\\text{Var}[X]}$ 具有和 $X$ 相同的单位，更直观。\n",
    "\n",
    "例子：投资例子中的方差：\n",
    "\n",
    "$$\n",
    "\\text{Var}[X] = 0.5\\cdot 0^2 + 0.4\\cdot 2^2 + 0.1\\cdot 10^2 - 1.8^2 = 8.36.\n",
    "$$\n",
    "\n",
    "说明投资虽然期望收益高，但波动性极大 → 风险高。\n",
    "\n",
    "---\n",
    "\n",
    "## 5. 多元情况：均值向量与协方差矩阵\n",
    "\n",
    "* 对向量随机变量 $\\mathbf{x}$，期望就是分量逐一的平均：\n",
    "\n",
    "  $$\n",
    "  \\mu = E[\\mathbf{x}] \\quad (\\mu_i = E[x_i]).\n",
    "  $$\n",
    "* 协方差矩阵：\n",
    "\n",
    "  $$\n",
    "  \\Sigma = E\\big[(\\mathbf{x}-\\mu)(\\mathbf{x}-\\mu)^T\\big].\n",
    "  $$\n",
    "* 性质：对任意向量 $\\mathbf{v}$，\n",
    "\n",
    "  $$\n",
    "  \\mathbf{v}^T \\Sigma \\mathbf{v} = \\text{Var}(\\mathbf{v}^T\\mathbf{x}).\n",
    "  $$\n",
    "\n",
    "  这表示我们能通过 $\\Sigma$ 计算任何线性组合的方差。\n",
    "* 协方差矩阵的对角线是方差，非对角线表示变量之间的相关性（0=无关，正/负值表示正/负相关）。\n",
    "\n",
    "---\n",
    "\n",
    "## 6. 总结\n",
    "\n",
    "这一节的主线：\n",
    "\n",
    "1. **期望**：平均值，衡量“长期收益”。\n",
    "2. **效用期望**：考虑心理价值，效用函数可非线性。\n",
    "3. **方差**：衡量不确定性/风险。\n",
    "4. **多元扩展**：期望向量、协方差矩阵，用来刻画多个变量的均值和相关性。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f83b12b",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef20f49c",
   "metadata": {},
   "source": [
    "\n",
    "### 1. 什么时候更多数据能把不确定性降到任意低？\n",
    "\n",
    "**例子**：掷一枚可能存在偏差的硬币。\n",
    "\n",
    "* 我们不知道硬币正面朝上的真实概率 $p$。\n",
    "* 如果我们不断收集掷硬币的数据（例如上万次投掷），我们就可以把对 $p$ 的估计精确到非常小的误差。\n",
    "* 这时的不确定性来自 **参数未知**，属于 **epistemic uncertainty**。随着数据量无限增大，我们对参数的估计可以无限逼近真实值。\n",
    "\n",
    "➡️ 解释：这是 **模型参数的不确定性**，可以通过数据收集逐渐消除。\n",
    "\n",
    "---\n",
    "\n",
    "### 2. 什么时候更多数据只能降低到一定程度？\n",
    "\n",
    "**例子**：预测下一次公平硬币投掷的结果。\n",
    "\n",
    "* 即使我们完全知道概率 $p=0.5$，下一次投掷结果仍然不可预测，只能说有 50% 的概率是正面。\n",
    "* 这种不确定性来自事件本身的 **随机性 (aleatoric uncertainty)**，数据再多也无法消除。\n",
    "\n",
    "➡️ 解释：这种不确定性是问题固有的噪声，无法通过收集更多数据进一步减少。\n",
    "\n",
    "* 在这个例子里，收集数据最多只能让我们确定“硬币是公平的”，之后不确定性停留在 $p=0.5$ 上，再也无法减少。\n",
    "\n",
    "---\n",
    "\n",
    "## 总结：\n",
    "\n",
    "1. **更多数据可无限降低的不确定性** → 参数未知 (epistemic)。例：硬币偏向概率估计。\n",
    "2. **更多数据无法完全消除的不确定性** → 问题固有随机性 (aleatoric)。例：下一次硬币投掷结果。\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde2c54d",
   "metadata": {},
   "source": [
    "设 $X_i\\sim \\text{Bernoulli}(p)$ 表示第 $i$ 次掷硬币是否为正面（1 为正面，0 为反面），独立同分布。\n",
    "用样本频率\n",
    "\n",
    "$$\n",
    "\\hat p=\\frac1n\\sum_{i=1}^n X_i\n",
    "$$\n",
    "\n",
    "估计正面概率 $p$。\n",
    "\n",
    "## (1) 方差随样本数的缩放\n",
    "\n",
    "$$\n",
    "\\mathbb E[\\hat p]=p,\\qquad \n",
    "\\operatorname{Var}(\\hat p)=\\operatorname{Var}\\!\\left(\\frac1n\\sum X_i\\right)\n",
    "=\\frac{1}{n^2}\\sum \\operatorname{Var}(X_i)\n",
    "=\\frac{n\\cdot p(1-p)}{n^2}=\\frac{p(1-p)}{n}.\n",
    "$$\n",
    "\n",
    "→ 方差 **$O(1/n)$**；样本数翻 10 倍，方差缩至 1/10。最坏情况下 $p(1-p)\\le 1/4$。\n",
    "\n",
    "## (2) 用切比雪夫不等式给出偏离期望的上界\n",
    "\n",
    "对任意 $\\varepsilon>0$：\n",
    "\n",
    "$$\n",
    "\\Pr\\!\\left(|\\hat p-p|\\ge \\varepsilon\\right)\n",
    "\\le \\frac{\\operatorname{Var}(\\hat p)}{\\varepsilon^2}\n",
    "= \\frac{p(1-p)}{n\\varepsilon^2}\n",
    "\\le \\frac{1}{4n\\varepsilon^2}.\n",
    "$$\n",
    "\n",
    "这是分布无关（只用到了方差）的保守上界。\n",
    "\n",
    "## (3) 与中心极限定理（CLT）的关系\n",
    "\n",
    "CLT 给出更精细的近似：\n",
    "\n",
    "$$\n",
    "\\sqrt{n}\\,\\frac{\\hat p-p}{\\sqrt{p(1-p)}} \\ \\xrightarrow{d}\\ \\mathcal N(0,1),\n",
    "$$\n",
    "\n",
    "等价地，\n",
    "\n",
    "$$\n",
    "\\hat p \\approx \\mathcal N\\!\\left(p,\\ \\frac{p(1-p)}{n}\\right)\\quad (n\\ \\text{大}).\n",
    "$$\n",
    "\n",
    "因此可得近似置信区间\n",
    "\n",
    "$$\n",
    "\\hat p \\pm z_{\\alpha/2}\\sqrt{\\frac{p(1-p)}{n}}\n",
    "$$\n",
    "\n",
    "（实际常用 $\\hat p$ 代替 $p$ 做 plug-in）。\n",
    "和切比雪夫相比，CLT 在样本足够大时给出**更紧**的概率界与区间（例如 95% 时用 $z_{0.025}\\approx1.96$，而切比雪夫要 $k\\approx 4.47$ 才到 95%）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "97857242",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO exercises 5-8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
