{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48616d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from typing import Tuple\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39ec545",
   "metadata": {},
   "source": [
    "## 1. Image Classification Task & Dataset\n",
    "\n",
    "**Task**: Given an input image `x`, predict a label `y` from a fixed set of classes.\n",
    "\n",
    "**Challenges**:\n",
    "- Viewpoint variation\n",
    "- Illumination changes\n",
    "- Background clutter\n",
    "- Occlusion\n",
    "- Deformation\n",
    "- Intraclass variation\n",
    "\n",
    "In practice, large datasets (e.g., ImageNet, CIFAR-10) play a crucial role in\n",
    "training powerful image classifiers.\n",
    "\n",
    "In this notebook we'll use **CIFAR-10**:\n",
    "- 60,000 color images of size 32×32\n",
    "- 10 classes (airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck)\n",
    "- 50,000 for training, 10,000 for test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b54d1235",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [00:38<00:00, 4.48MB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(50000,\n",
       " 5000,\n",
       " 10000,\n",
       " ['airplane',\n",
       "  'automobile',\n",
       "  'bird',\n",
       "  'cat',\n",
       "  'deer',\n",
       "  'dog',\n",
       "  'frog',\n",
       "  'horse',\n",
       "  'ship',\n",
       "  'truck'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform = T.Compose([\n",
    "    T.ToTensor(),  # [0, 1]\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "num_train = len(train_dataset)\n",
    "num_val = 5000\n",
    "num_train_split = num_train - num_val\n",
    "\n",
    "train_split, val_split = random_split(train_dataset, [num_train_split, num_val])\n",
    "\n",
    "train_loader = DataLoader(train_split, batch_size=128, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_split, batch_size=128, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = train_dataset.classes\n",
    "len(train_dataset), len(val_split), len(test_dataset), classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f053b6a",
   "metadata": {},
   "source": [
    "## 2. Nearest Neighbor and k-Nearest Neighbor\n",
    "\n",
    "### 2.1 1-Nearest Neighbor (1-NN)\n",
    "\n",
    "**Training**:\n",
    "- Simply memorize all training examples and their labels.\n",
    "\n",
    "**Prediction for a test example** `x_test`:\n",
    "1. Compute distance between `x_test` and each training sample `x_i`.\n",
    "2. Find the nearest training example.\n",
    "3. Output its label.\n",
    "\n",
    "Time complexity:\n",
    "- Training: O(1)\n",
    "- Prediction: O(N_train × N_test) — very slow when N is large.\n",
    "\n",
    "### 2.2 Distance Metrics\n",
    "\n",
    "For vectors `x, y ∈ R^D`:\n",
    "\n",
    "- L1 (Manhattan):  $$d_1(x, y) = \\sum_i |x_i - y_i| $$\n",
    "- L2 (Euclidean):  $$d_2(x, y) = \\sqrt{\\sum_i (x_i - y_i)^2} $$\n",
    "- General Lp:      $$d_p(x, y) = (\\sum_i |x_i - y_i|^p)^{1/p} $$\n",
    "\n",
    "When $$p → ∞$$, we get **Chebyshev distance**.\n",
    "\n",
    "### 2.3 k-Nearest Neighbor (k-NN)\n",
    "\n",
    "- Instead of just 1 nearest neighbor, choose the `k` closest training samples.\n",
    "- Predict by **majority vote** over these `k` labels.\n",
    "\n",
    "`k` and the choice of distance metric are **hyperparameters**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7404ed84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 3072), (1000, 3072))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To keep it simple & fast, we only use a subset of training data for KNN.\n",
    "subset_size = 5000\n",
    "indices = torch.randperm(num_train_split)[:subset_size]\n",
    "knn_subset = torch.utils.data.Subset(train_split, indices)\n",
    "\n",
    "# Flatten images to vectors\n",
    "def dataset_to_numpy(dataset):\n",
    "    X_list, y_list = [], []\n",
    "    for img, label in dataset:\n",
    "        X_list.append(img.view(-1).numpy())\n",
    "        y_list.append(label)\n",
    "    X = np.stack(X_list, axis=0)  # [N, D]\n",
    "    y = np.array(y_list)          # [N]\n",
    "    return X, y\n",
    "\n",
    "X_train_knn, y_train_knn = dataset_to_numpy(knn_subset)\n",
    "\n",
    "# Also prepare a small validation subset for KNN evaluation\n",
    "val_subset_size = 1000\n",
    "val_indices = torch.randperm(len(val_split))[:val_subset_size]\n",
    "val_subset = torch.utils.data.Subset(val_split, val_indices)\n",
    "X_val_knn, y_val_knn = dataset_to_numpy(val_subset)\n",
    "\n",
    "X_train_knn.shape, X_val_knn.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f74560a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_distance_batch(X: np.ndarray, Y: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute pairwise L2 distances between two sets of vectors:\n",
    "    X: [N, D]\n",
    "    Y: [M, D]\n",
    "    returns: [N, M]\n",
    "    \"\"\"\n",
    "    # (x - y)^2 = x^2 + y^2 - 2 x·y\n",
    "    X_norm = np.sum(X ** 2, axis=1, keepdims=True)     # [N, 1]\n",
    "    Y_norm = np.sum(Y ** 2, axis=1, keepdims=True).T   # [1, M]\n",
    "    cross = X @ Y.T                                    # [N, M]\n",
    "    dists = np.sqrt(X_norm + Y_norm - 2 * cross + 1e-8)\n",
    "    return dists\n",
    "\n",
    "\n",
    "def knn_predict(\n",
    "    X_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    "    X_test: np.ndarray,\n",
    "    k: int = 1,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    k-NN classifier.\n",
    "    X_train: [N_train, D]\n",
    "    y_train: [N_train]\n",
    "    X_test: [N_test, D]\n",
    "    \"\"\"\n",
    "    dists = l2_distance_batch(X_test, X_train)  # [N_test, N_train]\n",
    "    # indices of k nearest neighbors\n",
    "    knn_idx = np.argpartition(dists, k, axis=1)[:, :k]  # [N_test, k]\n",
    "    knn_labels = y_train[knn_idx]                       # [N_test, k]\n",
    "    # majority vote\n",
    "    preds = []\n",
    "    for labels in knn_labels:\n",
    "        values, counts = np.unique(labels, return_counts=True)\n",
    "        preds.append(values[np.argmax(counts)])\n",
    "    return np.array(preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7afbb5",
   "metadata": {},
   "source": [
    "这段代码实现的是k-NN算法中的**多数投票（majority vote）**过程。让我用具体例子来说明：\n",
    "\n",
    "## 多数投票过程\n",
    "\n",
    "假设我们有一个测试样本，它的k=5个最近邻的标签如下：\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7191a68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设某个测试样本的5个最近邻标签\n",
    "labels = np.array([2, 1, 2, 0, 2])  # 来自knn_labels中的一行\n",
    "\n",
    "# 执行多数投票\n",
    "values, counts = np.unique(labels, return_counts=True)\n",
    "print(\"values:\", values)   # [0, 1, 2] - 出现的唯一标签\n",
    "print(\"counts:\", counts)   # [1, 1, 3] - 对应的出现次数\n",
    "\n",
    "# 找出现次数最多的标签\n",
    "most_frequent_idx = np.argmax(counts)  # 2 (counts中最大值的索引)\n",
    "prediction = values[most_frequent_idx]  # values[2] = 2\n",
    "print(\"prediction:\", prediction)  # 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063800cd",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 完整流程示例\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee77639d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设我们有3个测试样本，k=3\n",
    "knn_labels = np.array([\n",
    "    [1, 1, 0],  # 测试样本0的3个近邻标签\n",
    "    [2, 1, 2],  # 测试样本1的3个近邻标签  \n",
    "    [0, 0, 1],  # 测试样本2的3个近邻标签\n",
    "])\n",
    "\n",
    "preds = []\n",
    "for labels in knn_labels:\n",
    "    print(f\"处理标签: {labels}\")\n",
    "    values, counts = np.unique(labels, return_counts=True)\n",
    "    print(f\"  唯一值: {values}, 计数: {counts}\")\n",
    "    \n",
    "    most_frequent = values[np.argmax(counts)]\n",
    "    print(f\"  预测结果: {most_frequent}\")\n",
    "    preds.append(most_frequent)\n",
    "    print()\n",
    "\n",
    "print(\"最终预测:\", np.array(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b090f428",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**输出：**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c32991",
   "metadata": {
    "vscode": {
     "languageId": ""
    }
   },
   "outputs": [],
   "source": [
    "处理标签: [1 1 0]\n",
    "  唯一值: [0 1], 计数: [1 2]\n",
    "  预测结果: 1\n",
    "\n",
    "处理标签: [2 1 2]  \n",
    "  唯一值: [1 2], 计数: [1 2]\n",
    "  预测结果: 2\n",
    "\n",
    "处理标签: [0 0 1]\n",
    "  唯一值: [0 1], 计数: [2 1]  \n",
    "  预测结果: 0\n",
    "\n",
    "最终预测: [1 2 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b816667",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 核心思想\n",
    "\n",
    "1. **统计频次**：`np.unique()` 统计每个标签的出现次数\n",
    "2. **找最大值**：`np.argmax(counts)` 找出现最多的标签的索引\n",
    "3. **返回预测**：`values[argmax_idx]` 得到最终预测标签\n",
    "\n",
    "这样，每个测试样本的预测就是其k个最近邻中**出现次数最多的类别**，这就是k-NN的多数投票机制。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cd42d7",
   "metadata": {},
   "source": [
    "这行代码是在实现 **k-NN (k近邻)** 算法中的关键步骤：**找到每个测试样本的 k 个最近邻**。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe473a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_idx = np.argpartition(dists, k, axis=1)[:, :k]  # [N_test, k]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f9c101",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**逐步解析：**\n",
    "\n",
    "1. **`dists`**: 形状为 `[N_test, N_train]` 的距离矩阵\n",
    "   - `dists[i, j]` = 第i个测试样本到第j个训练样本的距离\n",
    "\n",
    "2. **`np.argpartition(dists, k, axis=1)`**: \n",
    "   - 对每一行（每个测试样本）进行部分排序\n",
    "   - 将最小的 k 个元素放到前 k 个位置\n",
    "   - 返回**索引**而不是值\n",
    "   - **不完全排序**，只保证前k个是最小的\n",
    "\n",
    "3. **`[:, :k]`**: 只取前 k 列，得到每个测试样本的 k 个最近邻的索引\n",
    "\n",
    "**举例说明：**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f1970a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设有3个测试样本，5个训练样本，k=2\n",
    "dists = np.array([\n",
    "    [3.1, 1.5, 4.2, 2.0, 3.8],  # 测试样本0到各训练样本的距离\n",
    "    [2.1, 3.5, 1.2, 4.0, 1.8],  # 测试样本1到各训练样本的距离  \n",
    "    [1.9, 2.5, 3.1, 1.1, 2.8],  # 测试样本2到各训练样本的距离\n",
    "])\n",
    "\n",
    "knn_idx = np.argpartition(dists, 2, axis=1)[:, :2]\n",
    "# 结果可能是：\n",
    "# [[1, 3],  # 测试样本0的2个最近邻：训练样本1和3\n",
    "#  [2, 4],  # 测试样本1的2个最近邻：训练样本2和4  \n",
    "#  [3, 0]]  # 测试样本2的2个最近邻：训练样本3和0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c923f405",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "这样就得到了每个测试样本对应的 k 个最近邻训练样本的**索引**，用于后续的多数投票预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d1d7b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1, val accuracy=0.2620, time=0.31s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "y_val_pred_k1 = knn_predict(X_train_knn, y_train_knn, X_val_knn, k=1)\n",
    "acc_k1 = (y_val_pred_k1 == y_val_knn).mean()\n",
    "end = time.time()\n",
    "\n",
    "print(f\"k=1, val accuracy={acc_k1:.4f}, time={end-start:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0e6e0b",
   "metadata": {},
   "source": [
    "## 3. Hyperparameters, Validation Set, and Cross-Validation\n",
    "\n",
    "In k-NN, important **hyperparameters** include:\n",
    "- `k`: number of neighbors\n",
    "- distance metric (L1, L2, etc.)\n",
    "\n",
    "We don't know the best choice a priori.\n",
    "Instead we:\n",
    "1. Split data into **train / validation / test**.\n",
    "2. Use **train** to fit parameters (here: just store samples).\n",
    "3. Use **validation** to choose hyperparameters.\n",
    "4. Finally evaluate the chosen model once on **test**.\n",
    "\n",
    "### Cross-validation (CV)\n",
    "\n",
    "For smaller datasets:\n",
    "- Split training data into K folds.\n",
    "- For each hyperparameter setting:\n",
    "  - Train on K-1 folds\n",
    "  - Validate on the remaining fold\n",
    "  - Average performance across folds\n",
    "\n",
    "For large deep learning datasets, CV is often too expensive,\n",
    "so we typically:\n",
    "- Use a single train/val split\n",
    "- Possibly repeat experiments if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "deaba2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1, val accuracy=0.2620, time=0.21s\n",
      "k=3, val accuracy=0.2460, time=0.08s\n",
      "k=5, val accuracy=0.2510, time=0.11s\n",
      "k=7, val accuracy=0.2660, time=0.09s\n",
      "k=9, val accuracy=0.2740, time=0.07s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: np.float64(0.262),\n",
       " 3: np.float64(0.246),\n",
       " 5: np.float64(0.251),\n",
       " 7: np.float64(0.266),\n",
       " 9: np.float64(0.274)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate_knn_for_k_list(ks):\n",
    "    results = {}\n",
    "    for k in ks:\n",
    "        start = time.time()\n",
    "        y_val_pred = knn_predict(X_train_knn, y_train_knn, X_val_knn, k=k)\n",
    "        acc = (y_val_pred == y_val_knn).mean()\n",
    "        end = time.time()\n",
    "        print(f\"k={k}, val accuracy={acc:.4f}, time={end-start:.2f}s\")\n",
    "        results[k] = acc\n",
    "    return results\n",
    "\n",
    "k_list = [1, 3, 5, 7, 9]\n",
    "knn_results = evaluate_knn_for_k_list(k_list)\n",
    "knn_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c95494",
   "metadata": {},
   "source": [
    "你观察得很仔细！但在这个代码中，**验证集实际上是固定的**，每次k-NN实验都使用相同的验证集。\n",
    "\n",
    "让我分析一下代码：\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63548476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在函数外部，验证集已经固定创建\n",
    "val_subset_size = 1000\n",
    "val_indices = torch.randperm(len(val_split))[:val_subset_size]  # 固定的随机索引\n",
    "val_subset = torch.utils.data.Subset(val_split, val_indices)\n",
    "X_val_knn, y_val_knn = dataset_to_numpy(val_subset)  # 固定的验证集\n",
    "\n",
    "def evaluate_knn_for_k_list(ks):\n",
    "    results = {}\n",
    "    for k in ks:\n",
    "        # 每次都使用相同的 X_val_knn, y_val_knn\n",
    "        y_val_pred = knn_predict(X_train_knn, y_train_knn, X_val_knn, k=k)\n",
    "        acc = (y_val_pred == y_val_knn).mean()\n",
    "        results[k] = acc\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787802d1",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 这样做是正确的！\n",
    "\n",
    "**原因：**\n",
    "1. **超参数选择**：我们要比较不同k值的性能，必须在**相同的验证集**上测试\n",
    "2. **公平比较**：如果每次k都用不同验证集，就无法知道性能差异是由于k的不同还是数据的不同\n",
    "3. **标准做法**：在机器学习中，超参数调优时验证集是固定的\n",
    "\n",
    "## 如果要使用交叉验证\n",
    "\n",
    "如果你想要更robust的评估，应该使用交叉验证：\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efef691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_knn_cv(k, n_folds=5):\n",
    "    # 将训练数据分成n_folds份\n",
    "    fold_size = len(X_train_knn) // n_folds\n",
    "    accuracies = []\n",
    "    \n",
    "    for fold in range(n_folds):\n",
    "        # 每一折作为验证集\n",
    "        val_start = fold * fold_size\n",
    "        val_end = (fold + 1) * fold_size\n",
    "        \n",
    "        val_X = X_train_knn[val_start:val_end]\n",
    "        val_y = y_train_knn[val_start:val_end]\n",
    "        \n",
    "        train_X = np.concatenate([X_train_knn[:val_start], X_train_knn[val_end:]])\n",
    "        train_y = np.concatenate([y_train_knn[:val_start], y_train_knn[val_end:]])\n",
    "        \n",
    "        pred = knn_predict(train_X, train_y, val_X, k)\n",
    "        acc = (pred == val_y).mean()\n",
    "        accuracies.append(acc)\n",
    "    \n",
    "    return np.mean(accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91e95fb",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "但对于大数据集，通常使用单一的train/val/test分割就足够了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "641ee7ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ks = sorted(knn_results.keys())\n",
    "accs = [knn_results[k] for k in ks]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(ks, accs, marker=\"o\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Validation accuracy\")\n",
    "plt.title(\"k-NN on CIFAR-10 (subset)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfa693b",
   "metadata": {},
   "source": [
    "## 4. Limitations of k-NN\n",
    "\n",
    "**Empirical issues on image classification**:\n",
    "- High error rate\n",
    "- Very slow prediction time for large datasets\n",
    "- Needs to store all training examples\n",
    "\n",
    "Main reasons:\n",
    "1. Distance in raw pixel space is not semantically meaningful\n",
    "   - Two images that look very different can still have small pixel-wise distance\n",
    "   - Two very similar images can have large pixel-wise distance under some noise\n",
    "2. Curse of dimensionality\n",
    "   - In high dimensions, distances become less informative\n",
    "   - Computational complexity is high\n",
    "\n",
    "These motivate **parametric** models, where we learn a small number of\n",
    "parameters (e.g., weights of a linear classifier) to summarize the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e800ee",
   "metadata": {},
   "source": [
    "## 5. Linear Classifier\n",
    "\n",
    "We flatten the image `x ∈ R^D` and want to predict one of `C` classes.\n",
    "\n",
    "We introduce parameters:\n",
    "- Weight matrix $$ W ∈ R^{C × D} $$\n",
    "- Bias vector $$ b ∈ R^C $$\n",
    "\n",
    "The **score vector** is:\n",
    "$$\n",
    "s = f(x; W, b) = Wx + b  \\quad (s ∈ R^C)\n",
    "$$\n",
    "\n",
    "Interpretations:\n",
    "- Algebraic: a linear transformation followed by a translation\n",
    "- Visual: each row of W can be seen as a \"template\" for a class\n",
    "- Geometric: each class defines a hyperplane; classification partitions\n",
    "  the data space into regions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9325a05e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearClassifier(\n",
       "  (fc): Linear(in_features=3072, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LinearClassifier(nn.Module):\n",
    "    def __init__(self, input_dim: int, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(input_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, 3, 32, 32]\n",
    "        x = x.view(x.size(0), -1)  # flatten\n",
    "        scores = self.fc(x)        # [B, C]\n",
    "        return scores\n",
    "\n",
    "input_dim = 3 * 32 * 32\n",
    "num_classes = 10\n",
    "model = LinearClassifier(input_dim, num_classes)\n",
    "model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66471234",
   "metadata": {},
   "source": [
    "## 6. SVM (Hinge) Loss for Linear Classifier\n",
    "\n",
    "For an input x with true label y (0 ≤ y < C), let scores be:\n",
    "$$\n",
    "s = f(x; W, b) ∈ R^C\n",
    "$$\n",
    "\n",
    "Multiclass SVM / hinge loss:\n",
    "$$\n",
    "L_i = \\sum_{j ≠ y} \\max(0,\\; s_j - s_y + \\Delta),\n",
    "$$\n",
    "where typically $ \\Delta = 1 $.\n",
    "\n",
    "Dataset loss is the average:\n",
    "$$\n",
    "L = \\frac{1}{N} \\sum_{i=1}^N L_i.\n",
    "$$\n",
    "\n",
    "Intuition:\n",
    "$$\n",
    "L_i = \\sum_{j ≠ y} \\max(0,\\; s_j - s_y + \\Delta),\n",
    "$$\n",
    "where typically $\\Delta = 1$.\n",
    "\n",
    "Dataset loss is the average:\n",
    "$$\n",
    "L = \\frac{1}{N} \\sum_{i=1}^N L_i.\n",
    "$$\n",
    "\n",
    "\n",
    "Intuition:\n",
    "- We want the **correct class score** $s_y$ to be larger than every\n",
    "  incorrect score $s_j$ by at least a margin of 1.\n",
    "\n",
    "Questions to think about:\n",
    "- What is the minimum and maximum possible value of $L_i$?\n",
    "- What happens at initialization when all scores are close to zero?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7ad211",
   "metadata": {},
   "source": [
    "## 6. 线性分类器的SVM（铰链）损失\n",
    "\n",
    "对于输入 x 和真实标签 y（0 ≤ y < C），设分数为：\n",
    "$$\n",
    "s = f(x; W, b) ∈ R^C\n",
    "$$\n",
    "\n",
    "多类别SVM/铰链损失：\n",
    "$$\n",
    "L_i = \\sum_{j ≠ y} \\max(0,\\; s_j - s_y + \\Delta),\n",
    "$$\n",
    "其中通常 $\\Delta = 1$。\n",
    "\n",
    "数据集损失是平均值：\n",
    "$$\n",
    "L = \\frac{1}{N} \\sum_{i=1}^N L_i.\n",
    "$$\n",
    "\n",
    "**直观理解：**\n",
    "- 我们希望**正确类别的分数** $s_y$ 比每个错误类别的分数 $s_j$ 至少大 1 个边距。\n",
    "\n",
    "**思考问题：**\n",
    "- $L_i$ 的最小值和最大值可能是多少？\n",
    "- 当初始化时所有分数都接近零时会发生什么？\n",
    "\n",
    "**详细解释：**\n",
    "\n",
    "1. **损失函数的含义**：\n",
    "   - 对于每个样本，我们计算正确类别分数与所有错误类别分数的差异\n",
    "   - 如果正确类别分数足够高（比错误类别分数高1以上），损失为0\n",
    "   - 否则，损失随着分数差异的减小而增加\n",
    "\n",
    "2. **边距的作用**：\n",
    "   - $\\Delta = 1$ 定义了一个\"安全边距\"\n",
    "   - 不仅要求正确类别分数最高，还要求至少高出1个单位\n",
    "\n",
    "3. **实际应用**：\n",
    "   - 这种损失函数鼓励模型产生明确的预测\n",
    "   - 有助于提高分类的鲁棒性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55c8be5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_hinge_loss(scores: torch.Tensor, y: torch.Tensor, margin: float = 1.0):\n",
    "    \"\"\"\n",
    "    scores: [B, C]\n",
    "    y: [B]  (ground truth labels, 0..C-1)\n",
    "    \"\"\"\n",
    "    B, C = scores.shape\n",
    "    # correct class scores: [B, 1]\n",
    "    correct_scores = scores[torch.arange(B), y].unsqueeze(1)\n",
    "    # compute margins: [B, C]\n",
    "    margins = scores - correct_scores + margin\n",
    "    margins[torch.arange(B), y] = 0.0  # ignore correct class\n",
    "    # hinge\n",
    "    loss = torch.clamp(margins, min=0.0)\n",
    "    return loss.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24949092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "[SVM] epoch 1/3, train loss=0.6026, val acc=0.3320\n",
      "[SVM] epoch 2/3, train loss=0.5109, val acc=0.3472\n",
      "[SVM] epoch 3/3, train loss=0.4903, val acc=0.3508\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "svm_model = LinearClassifier(input_dim, num_classes).to(device)\n",
    "optimizer = torch.optim.SGD(svm_model.parameters(), lr=1e-3, momentum=0.9)\n",
    "num_epochs = 3  # for demo\n",
    "\n",
    "def evaluate_accuracy(model, data_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            scores = model(X)\n",
    "            preds = scores.argmax(dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    return correct / total\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    svm_model.train()\n",
    "    running_loss = 0.0\n",
    "    for X, y in train_loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        scores = svm_model(X)\n",
    "        loss = multiclass_hinge_loss(scores, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * X.size(0)\n",
    "\n",
    "    train_loss = running_loss / len(train_loader.dataset)\n",
    "    val_acc = evaluate_accuracy(svm_model, val_loader)\n",
    "    print(f\"[SVM] epoch {epoch+1}/{num_epochs}, train loss={train_loss:.4f}, val acc={val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809546bd",
   "metadata": {},
   "source": [
    "## 7. Softmax Classifier and Cross-Entropy Loss\n",
    "\n",
    "Linear classifier outputs raw scores $s ∈ R^C$.\n",
    "We convert scores to probabilities via **softmax**:\n",
    "\n",
    "$$\n",
    "q_k = P(Y = k | X = x) =\n",
    "\\frac{\\exp(s_k)}{\\sum_{j} \\exp(s_j)}.\n",
    "$$\n",
    "\n",
    "Given true label y, the loss is the **negative log-likelihood**:\n",
    "\n",
    "$$\n",
    "L_i = -\\log q_{y}\n",
    "    = -\\log \\frac{\\exp(s_y)}{\\sum_j \\exp(s_j)}.\n",
    "$$\n",
    "\n",
    "This is exactly the **cross-entropy** between:\n",
    "- The one-hot ground-truth distribution p(x)\n",
    "- The predicted distribution q(x)\n",
    "\n",
    "At initialization when all scores are equal:\n",
    "$$\n",
    "q_k = \\frac{1}{C}, \\quad\n",
    "L_i = -\\log\\frac{1}{C} = \\log C.\n",
    "$$\n",
    "\n",
    "For C=10, this is approximately 2.3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c5e5632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_probs: tensor([[-1.4644, -0.4644, -1.9644],\n",
      "        [-1.2019, -1.1019, -1.0019]])\n",
      "y: tensor([1, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.7332), tensor(0.7332))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def manual_cross_entropy_loss(scores: torch.Tensor, y: torch.Tensor):\n",
    "    \"\"\"\n",
    "    scores: [B, C] (logits)\n",
    "    y: [B]\n",
    "    \"\"\"\n",
    "    # log-softmax\n",
    "    log_probs = F.log_softmax(scores, dim=1)  # [B, C]\n",
    "    print(\"log_probs:\", log_probs)\n",
    "    print(\"y:\", y)\n",
    "    # pick the log-prob of correct class\n",
    "    loss = -log_probs[torch.arange(scores.size(0)), y]\n",
    "    return loss.mean()\n",
    "\n",
    "# Compare with built-in CrossEntropyLoss\n",
    "ce_builtin = nn.CrossEntropyLoss()\n",
    "scores_demo = torch.tensor([[1.0, 2.0, 0.5],\n",
    "                            [0.1, 0.2, 0.3]])\n",
    "y_demo = torch.tensor([1, 2])\n",
    "\n",
    "loss_manual = manual_cross_entropy_loss(scores_demo, y_demo)\n",
    "loss_builtin = ce_builtin(scores_demo, y_demo)\n",
    "loss_manual, loss_builtin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bd5f72",
   "metadata": {},
   "source": [
    "这是一个很好的问题！让我详细解释这行代码是如何工作的：\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8898394b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = -log_probs[torch.arange(scores.size(0)), y]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51488ed",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 核心机制：高级索引（Advanced Indexing）\n",
    "\n",
    "这里使用了PyTorch的**高级索引**功能来选择正确类别的概率。\n",
    "\n",
    "### 逐步分解：\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f04c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设我们有一个具体的例子\n",
    "scores = torch.tensor([[1.0, 2.0, 0.5],    # 样本0的分数 [类别0, 类别1, 类别2]\n",
    "                      [0.1, 0.2, 0.3]])    # 样本1的分数\n",
    "\n",
    "y = torch.tensor([1, 2])  # 样本0的真实标签是1，样本1的真实标签是2\n",
    "\n",
    "# log_softmax后得到对数概率\n",
    "log_probs = F.log_softmax(scores, dim=1)\n",
    "# log_probs = [[-1.31, -0.31, -1.81],    # 样本0的对数概率\n",
    "#              [-1.20, -1.10, -1.00]]    # 样本1的对数概率\n",
    "\n",
    "# 创建行索引\n",
    "batch_indices = torch.arange(scores.size(0))  # [0, 1]\n",
    "\n",
    "# 高级索引选择\n",
    "selected = log_probs[batch_indices, y]\n",
    "# 等价于：log_probs[[0, 1], [1, 2]]\n",
    "# 选择：log_probs[0, 1] 和 log_probs[1, 2]\n",
    "# 结果：[-0.31, -1.00]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e75b2d0",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 可视化理解：\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cab363b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_probs矩阵：\n",
    "#       类别0   类别1   类别2\n",
    "# 样本0  -1.31   -0.31   -1.81   ← y[0]=1，选择log_probs[0,1]=-0.31\n",
    "# 样本1  -1.20   -1.10   -1.00   ← y[1]=2，选择log_probs[1,2]=-1.00\n",
    "\n",
    "print(\"batch_indices:\", torch.arange(scores.size(0)))  # [0, 1]\n",
    "print(\"y:\", y)                                          # [1, 2]\n",
    "print(\"selected:\", log_probs[torch.arange(scores.size(0)), y])  # [-0.31, -1.00]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7139db76",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 等价的其他写法：\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab86a874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 方法1：循环（效率低）\n",
    "selected_loop = []\n",
    "for i in range(len(y)):\n",
    "    selected_loop.append(log_probs[i, y[i]])\n",
    "\n",
    "# 方法2：使用gather函数\n",
    "selected_gather = log_probs.gather(1, y.unsqueeze(1)).squeeze(1)\n",
    "\n",
    "# 方法3：使用高级索引（推荐）\n",
    "selected_advanced = log_probs[torch.arange(len(y)), y]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f626567d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 为什么这样写有效？\n",
    "\n",
    "1. **`torch.arange(scores.size(0))`** 生成行索引 `[0, 1, 2, ..., B-1]`\n",
    "2. **`y`** 提供列索引，表示每个样本的真实标签\n",
    "3. **高级索引** `log_probs[行索引, 列索引]` 同时选择多个元素\n",
    "4. 结果是每个样本对应其真实类别的对数概率\n",
    "\n",
    "这种写法既简洁又高效，是PyTorch中处理这类问题的标准做法！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76ff3e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Softmax] epoch 1/5, train loss=23.7025, val acc=0.2910\n",
      "[Softmax] epoch 2/5, train loss=17.9099, val acc=0.2956\n",
      "[Softmax] epoch 3/5, train loss=18.7217, val acc=0.3046\n",
      "[Softmax] epoch 4/5, train loss=18.1426, val acc=0.2236\n",
      "[Softmax] epoch 5/5, train loss=17.4512, val acc=0.2744\n",
      "Test accuracy (Softmax linear classifier): 0.2629\n"
     ]
    }
   ],
   "source": [
    "softmax_model = LinearClassifier(input_dim, num_classes).to(device)\n",
    "optimizer = torch.optim.SGD(softmax_model.parameters(), lr=1e-1, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "num_epochs = 5  # small demo\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    softmax_model.train()\n",
    "    running_loss = 0.0\n",
    "    for X, y in train_loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        scores = softmax_model(X)\n",
    "        loss = criterion(scores, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * X.size(0)\n",
    "\n",
    "    train_loss = running_loss / len(train_loader.dataset)\n",
    "    val_acc = evaluate_accuracy(softmax_model, val_loader)\n",
    "    print(f\"[Softmax] epoch {epoch+1}/{num_epochs}, train loss={train_loss:.4f}, val acc={val_acc:.4f}\")\n",
    "\n",
    "test_acc = evaluate_accuracy(softmax_model, test_loader)\n",
    "print(f\"Test accuracy (Softmax linear classifier): {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6162d411",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "\"log_softmax_lastdim_kernel_impl\" not implemented for 'Long'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, scores, y \u001b[38;5;129;01min\u001b[39;00m examples:\n\u001b[32m     18\u001b[39m     svm_l = svm_loss_single(scores, y)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     ce_l = \u001b[43mce_loss_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m     \u001b[38;5;28mprint\u001b[39m(name, scores)\n\u001b[32m     21\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  SVM loss = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msvm_l\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mce_loss_single\u001b[39m\u001b[34m(scores, y)\u001b[39m\n\u001b[32m      7\u001b[39m scores = torch.tensor(scores).unsqueeze(\u001b[32m0\u001b[39m)\n\u001b[32m      8\u001b[39m y = torch.tensor([y])\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmanual_cross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m.item()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mmanual_cross_entropy_loss\u001b[39m\u001b[34m(scores, y)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mscores: [B, C] (logits)\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03my: [B]\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# log-softmax\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m log_probs = \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_softmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [B, C]\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mlog_probs:\u001b[39m\u001b[33m\"\u001b[39m, log_probs)\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33my:\u001b[39m\u001b[33m\"\u001b[39m, y)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/codebase/ml/learn_d2l/.venv/lib/python3.12/site-packages/torch/nn/functional.py:2245\u001b[39m, in \u001b[36mlog_softmax\u001b[39m\u001b[34m(input, dim, _stacklevel, dtype)\u001b[39m\n\u001b[32m   2243\u001b[39m     dim = _get_softmax_dim(\u001b[33m\"\u001b[39m\u001b[33mlog_softmax\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28minput\u001b[39m.dim(), _stacklevel)\n\u001b[32m   2244\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2245\u001b[39m     ret = \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlog_softmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2246\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2247\u001b[39m     ret = \u001b[38;5;28minput\u001b[39m.log_softmax(dim, dtype=dtype)\n",
      "\u001b[31mNotImplementedError\u001b[39m: \"log_softmax_lastdim_kernel_impl\" not implemented for 'Long'"
     ]
    }
   ],
   "source": [
    "def svm_loss_single(scores, y, margin=1.0):\n",
    "    scores = torch.tensor(scores).unsqueeze(0)  # [1, C]\n",
    "    y = torch.tensor([y])\n",
    "    return multiclass_hinge_loss(scores, y, margin=margin).item()\n",
    "\n",
    "def ce_loss_single(scores, y):\n",
    "    scores = torch.tensor(scores).unsqueeze(0)\n",
    "    y = torch.tensor([y])\n",
    "    return manual_cross_entropy_loss(scores, y).item()\n",
    "\n",
    "examples = [\n",
    "    (\"case1\", [10, -2, 3], 0),\n",
    "    (\"case2\", [10, 9, 9], 0),\n",
    "    (\"case3\", [10, -100, -100], 0),\n",
    "]\n",
    "\n",
    "for name, scores, y in examples:\n",
    "    svm_l = svm_loss_single(scores, y)\n",
    "    ce_l = ce_loss_single(scores, y)\n",
    "    print(name, scores)\n",
    "    print(f\"  SVM loss = {svm_l:.4f}\")\n",
    "    print(f\"  CE  loss = {ce_l:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9003ea02",
   "metadata": {},
   "source": [
    "## 9. Comparing SVM (Hinge) and Softmax (Cross-Entropy)\n",
    "\n",
    "- **SVM / Hinge loss**:\n",
    "  - Encourages a margin between correct and incorrect class scores.\n",
    "  - Once the margin is satisfied, further increasing \\(s_y - s_j\\) does not reduce loss.\n",
    "  - \"Margin-based\" — becomes \"happy\" when margins are satisfied.\n",
    "\n",
    "- **Softmax / CE loss**:\n",
    "  - Treats scores as unnormalized log-probabilities.\n",
    "  - Always pushes for higher probability on the correct class,\n",
    "    and lower probabilities on incorrect classes.\n",
    "  - Never fully happy — there is always room to improve probabilities.\n",
    "\n",
    "In practice:\n",
    "- Both are reasonable for linear classifiers.\n",
    "- For modern deep networks, **Cross-Entropy loss** is more commonly used.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
